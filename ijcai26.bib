@article{a1,
  title={Forecasting of Bitcoin Cryptocurrency Price using the Autoregressive Integrated Moving Average (ARIMA) Method},
  author={Nella Cornelya and Dian Cahyawati and Ning Eliyati and Robinson Sitepu and Eka Susanti and Novi Rustiana Dewi and Putra Bahtera Jaya Bangun},
  journal={Proceedings of the 3rd Sriwijaya International Conference on Basic and Applied Sciences, SICBAS 2023, November 3, 2023, Palembang, Indonesia},
  year={2024}
}

@article{a6,
  title={Predicting Cryptocurrency Price Using RNN and LSTM Method},
  author={Dzaki Mahadika Gunarto and Siti Sa’adah and Dody Q. Utama},
  journal={Jurnal Sisfokom (Sistem Informasi dan Komputer)},
  year={2023}
}

@article{a7,
  title={Performance Comparison of LSTM and GRU Methods in Predicting Cryptocurrency Closing Prices},
  author={Rayhan Satria Andromeda and Nurul Anisa Sri Winarsih},
  journal={SISTEMASI},
  year={2025}
}

@article{a8,
  title={Multi-Model Deep Learning Architecture for Cryptocurrency Forecasting: A Comparative Evaluation of CNN-LSTM, CNN-Bidirectional LSTM, and CNN-GRU},
  author={Agung Mulyo Widodo and Andika Wisnujati and M.F. Arrozi Adhikara and Nur Endah Rakhmawati and Hojjat Baghban},
  journal={2025 5th International Conference on Electronic and Electrical Engineering and Intelligent System (ICE3IS)},
  year={2025},
  pages={355-360}
}

@article{a9,
  title={Hybrid Deep Learning Model Integrating Attention Mechanism for the Accurate Prediction and Forecasting of the Cryptocurrency Market},
  author={Godfrey Joseph Saqware and Ismail B},
  journal={Operations Research Forum},
  year={2024},
  volume={5},
  pages={1-19}
}

@article{a10,
  title={Attention-augmented hybrid CNN-LSTM model for social media sentiment analysis in cryptocurrency investment decision-making},
  author={Dimple Tiwari and Bhoopesh Singh Bhati and Bharti Nagpal and Nazik Alturki and Lotta Bayisenge},
  journal={Scientific Reports},
  year={2025},
  volume={15}
}

@article{a11,
  title={Predicting Stock Prices with FinBERT-LSTM: Integrating News Sentiment Analysis},
  author={Wen jun Gu and Yi hao Zhong and Shi zun Li and Chang song Wei and Li ting Dong and Zhuo yue Wang and Chao Yan},
  journal={Proceedings of the 2024 8th International Conference on Cloud and Big Data Computing},
  year={2024}
}

@article{a12,
  title={Hybrid ARDL-MIDAS-Transformer time-series regressions for multi-topic crypto market sentiment driven by price and technology factors},
  author={Ioannis Chalkiadakis and Gareth W. Peters and Matthew Ames},
  journal={Digital Finance},
  year={2021},
  volume={5},
  pages={295--365}
}

@inproceedings{anh1,
  title={Transforming Stock Price Forecasting: Deep Learning Architectures and Strategic Feature Engineering},
  author={Nguyen Quoc Anh and Son Ha},
  booktitle={Modeling Decisions for Artificial Intelligence},
  year={2024}
}

@article{anh2,
  title={Phase Space Reconstructed Neural Ordinary Differential Equations Model for Stock Price Forecasting},
  author={Nguyen Quoc Anh and Son Ha and Hieu Thai},
  journal={Pacific Asia Conference on Information Systems (PACIS)},
  year={2024}
}

@article{hybrid1,
  title={Forecasting Cryptocurrency Prices Using LSTM, GRU, and Bi-Directional LSTM: A Deep Learning Approach},
  author={Phumudzo Lloyd Seabe and Claude Rodrigue Bambe Moutsinga and Edson Pindza},
  journal={Fractal and Fractional},
  year={2023}
}

@article{hybrid2,
  title={Ensemble Model Based on Deep Learning for Forecasting Crypto Asset Futures in Markets},
  author={Fayad Ali and Ravate Suryakant and Sunil Nimbore},
  journal={2023 3rd International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)},
  year={2023},
  pages={1-8}
}

@article{hybrid5,
  title={Stock Price Prediction with LLM-Guided Market Movement Signals and Transformer Model},
  author={Qizhao Chen},
  journal={FinTech and Sustainable Innovation},
  year={2025}
}

@article{clam,
  title={CLAM: A Synergistic Deep Learning Model for Multi-Step Stock Trend Forecasting},
  author={Nguyen Quoc Anh and Truong Gia Hy},
  journal={Intelligenza Artificiale},
  year={2025},
  volume={19},
  pages={52--65}
}

@article{a3,
  title={GhostNet: More Features From Cheap Operations},
  author={Kai Han and Yunhe Wang and Qi Tian and Jianyuan Guo and Chunjing Xu and Chang Xu},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={1577-1586}
}

@article{a4,
  title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  author={Mingxing Tan and Quoc V. Le},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.11946}
}

@article{a5,
  title={LeViT: a Vision Transformer in ConvNet’s Clothing for Faster Inference},
  author={Benjamin Graham and Alaaeldin El-Nouby and Hugo Touvron and Pierre Stock and Armand Joulin and Herv'e J'egou and Matthijs Douze},
  journal={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={12239-12249}
}

@article{a2,
  title={Searching for MobileNetV3},
  author={Andrew G. Howard and Mark Sandler and Grace Chu and Liang-Chieh Chen and Bo Chen and Mingxing Tan and Weijun Wang and Yukun Zhu and Ruoming Pang and Vijay Vasudevan and Quoc V. Le and Hartwig Adam},
  journal={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019},
  pages={1314-1324}
}

@article{extra,
  title={Decision trees and random forests.},
  author={Thijs Becker and Axel-Jan Rousseau and Melvin Geubbelmans and Tomasz Burzykowski and Dirk Valkenborg},
  journal={American journal of orthodontics and dentofacial orthopedics : official publication of the American Association of Orthodontists, its constituent societies, and the American Board of Orthodontics},
  year={2023},
  volume={164},
  number={6},
  pages={894-897}
}

@article{patchtst,
  title={A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
  author={Yuqi Nie and Nam H. Nguyen and Phanwadee Sinthong and Jayant Kalagnanam},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.14730}
}

@inproceedings{autoformer,
  title={Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting},
  author={Haixu Wu and Jiehui Xu and Jianmin Wang and Mingsheng Long},
  booktitle={Neural Information Processing Systems},
  year={2021}
}

@article{informer,
  title={Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},
  author={Haoyi Zhou and Shanghang Zhang and Jieqi Peng and Shuai Zhang and Jianxin Li and Hui Xiong and Wan Zhang},
  journal={ArXiv},
  year={2020},
  volume={abs/2012.07436}
}

@article{nisha,
  title={Analysis and price prediction of cryptocurrencies for historical and live data using ensemble-based neural networks},
  author={Nisha Rathee and Ankita Singh and Tanisha Sharda and Nimisha Goel and Mansi Aggarwal and Sanya Dudeja},
  journal={Knowledge and Information Systems},
  year={2023},
  volume={65},
  pages={4055-4084}
}

@inproceedings{attention,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  booktitle={Neural Information Processing Systems},
  year={2017}
}

@inproceedings{boo,
  title={Are Transformers Effective for Time Series Forecasting?},
  author={Ailing Zeng and Mu-Hwa Chen and L. Zhang and Qiang Xu},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}

@inproceedings{fedformer,
  title={FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting},
  author={Tian Zhou and Ziqing Ma and Qingsong Wen and Xue Wang and Liang Sun and Rong Jin},
  booktitle={International Conference on Machine Learning},
  year={2022}
}

@article{b1,
  title={A systematic review for transformer-based long-term series forecasting},
  author={Liyilei Su and Xumin Zuo and Rui Li and Xin Wang and Heng Zhao and Bingding Huang},
  journal={Artificial Intelligence Review},
  year={2023},
  volume={58}
}

@article{b2,
  title={Unlocking the black box: an in-depth review on interpretability, explainability, and reliability in deep learning},
  author={Emrullah Şahin and Naciye Nur Arslan and Durmuş {\"O}zdemir},
  journal={Neural Computing and Applications},
  year={2024},
  volume={37},
  pages={859--965}
}

@article{b3,
  title={Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting},
  author={Bryan Lim and Sercan {\"O}. Arik and Nicolas Loeff and Tomas Pfister},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.09363}
}

@article{b4,
  title={Evaluating the Performance of Machine Learning Algorithms in Financial Market Forecasting: A Comprehensive Survey},
  author={Lukas Ryll and Sebastian Seidens},
  journal={arXiv: Computational Finance},
  year={2019}
}

@article{b5,
  title={Artificial intelligence and classical statistical models for time series forecasting: a comprehensive review},
  author={Essam H. Houssein and Meran Mohamed and Eman M. G. Younis and Waleed M. Mohamed},
  journal={Journal of Big Data},
  year={2025},
  volume={12}
}

@article{b6,
  title={Portfolio Diversification, Hedge and Safe-Haven Properties in Cryptocurrency Investments and Financial Economics: A Systematic Literature Review},
  author={José Almeida and Tiago Cruz Gonçalves},
  journal={Journal of Risk and Financial Management},
  year={2022}
}

@article{b7,
  title={Generative AI-Based Stochastic Forecasting Models for Predictive Analysis in High-Volatility, Multi-Asset Financial Markets},
  author={Karrar Hasan Dinar and Majid M. Manhosh and Zaid Ali Alasad and Ahmed Ali Hussein and Marwan Waheed Abdlhamed and Mohammed Gharkan Hayes Al-Bilawi and Mohammed Jumaah Raheem and Hashim H. Muqdad and Samer Adel Abd},
  journal={2025 3rd International Conference on Cyber Resilience (ICCR)},
  year={2025},
  pages={1-8}
}

@article{b8,
  title={On the efficiency and its drivers in the cryptocurrency market: the case of Bitcoin and Ethereum},
  author={Khaled Mokni and Ghassen El Montasser and Ahdi Noomen Ajmi and Elie Bouri},
  journal={Financial Innovation},
  year={2024},
  volume={10},
  pages={1-25}
}


% Additional missing entries
@inproceedings{itransformer,
  title={iTransformer: Inverted Transformers Are Effective for Time Series Forecasting},
  author={Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu, Haixu and Wang, Shiyu and Ma, Lintao and Long, Mingsheng},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@inproceedings{dlinear,
  title={Are Transformers Effective for Time Series Forecasting?},
  author={Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2023}
}

@inproceedings{revin,
  title={Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift},
  author={Kim, Taesung and Kim, Jinhee and Tae, Yunwon and Park, Cheonbok and Choi, Jang-Ho and Choo, Jaegul},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{prophet,
  title={Forecasting at Scale},
  author={Taylor, Sean J and Letham, Benjamin},
  journal={The American Statistician},
  volume={72},
  number={1},
  pages={37--45},
  year={2018}
}

@article{rlinear,
  title={Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping},
  author={Li, Zhe and Qi, Shiyi and Li, Yiduo and Xu, Zenglin},
  journal={arXiv preprint arXiv:2305.10721},
  year={2023}
}
